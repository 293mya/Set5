# HyperLogLog (A3) — Этапы 1–4

## Что где лежит

- `hyperloglog.cpp` — базовая реализация (Этап 1 + Этап 2) и запуск эксперимента для Этапа 3.
  - генерирует: `hll_stream_*.csv`, `hll_results_all_streams.csv`
- `hyperloglog_stage4.cpp` — моя улучшенная версия для Этапа 4 (сравнение baseline vs improved).
  - генерирует: `stage4_hll_stream_*.csv`, `stage4_hll_results_all_streams.csv`
- `analyze_hll.py` — построение графиков и подсчёт ошибок по CSV.

## Этап 3 — сравнение практики HyperLogLog с теорией (B = 10)

Я сравниваю **практические результаты** работы моего HyperLogLog с **теоретическими оценками** из задания.

---

### Что у меня есть на каждом шаге `t`

- точное число уникальных элементов: `F0^t` (`true_F0`)
- оценка HyperLogLog: `N_t` (`hll_estimate`)

Я считаю относительную ошибку:

err(t) = (N_t - F0^t) / F0^t

---

### Теоретические оценки из задания

В моём прогоне параметр:

- `B=10`, значит число регистров `m=2^B=1024`.

Теоретические ориентиры для масштаба относительной ошибки:

1.04 / sqrt(2^B) = 1.04 / sqrt(1024) = 1.04 / 32 ≈ 0.0325 (3.25%)

1.3  / sqrt(2^B) = 1.3  / 32        ≈ 0.0406 (4.06%)

То есть в среднем я ожидаю разброс ошибок порядка **3–4%**.

---

### 3.1 Точность — по шагам `t`

Я посмотрела ошибку по шагам: для каждого `t` взяла среднюю ошибку и стандартное отклонение по потокам.

Фиксируем ключевые шаги:

| t (items_processed) | средн. `F0^t` | средн. `N_t` | средн. ошибка `E(err)` | разброс `sigma(err)` |
|---:|---:|---:|---:|---:|
| 5 000   | 4 889  | 4 821  | −1.39% | 6.56% |
| 10 000  | 9 716  | 9 688  | −0.29% | 3.43% |
| 25 000  | 24 142 | 24 395 | +1.05% | 4.27% |
| 50 000  | 48 087 | 47 421 | −1.39% | 4.07% |
| 100 000 | 95 645 | 92 816 | −2.96% | 1.46% |

**Что это означает:**
- на самых ранних шагах (например, `t=5000`) разброс заметно больше — это ожидаемо, потому что данных мало;
- начиная со “середины” и ближе к концу оценка становится стабильнее;
- на финальном шаге `t=100000` разброс уже небольшой (`sigma(err) ≈ 1.46%`)

#### Проверка по теории по шагам
Если сравнивать `sigma(err)` на каждом шаге с теоретическими величинами:
- граница `1.04/sqrt(2^B) ≈ 3.25%` выполняется на **14 из 20 шагов**;
- граница `1.3/sqrt(2^B) ≈ 4.06%` выполняется на **17 из 20 шагов**.

Там, где `sigma(err)` чуть выше теории — это в основном ранние шаги и эффект того, что потоков мало (в моём прогоне потоков 5).

---

### 3.2 Общая точность (по всем потокам и всем шагам)

Итог:

- средняя относительная ошибка: `E(err) ≈ -0.012533 ⇒ -1.25%`
- стандартное отклонение относительной ошибки: `sigma(err) ≈ 0.028534 ⇒ 2.85%`

Сравнение с теорией для `B=10`:
- `sigma(err) ≈ 2.85%` меньше, чем `1.04/sqrt(1024) ≈ 3.25%`,
- и тем более меньше, чем `1.3/sqrt(1024) ≈ 4.06%`.

**Итог по точности:** в среднем HyperLogLog даёт очень близкую оценку, с небольшим занижением (~−1.25%), а разброс ошибок по масштабу совпадает с теорией

---

### 3.3 Стабильность оценки — что видно на Графике №2

На Графике №2:
- `E(N_t)` — средняя оценка по потокам,
- полоса неопределённости: `E(N_t) ± sigma(N_t)`.

По графику видно:
- полоса `± sigma(N_t)` ведёт себя ровно, поэтому оценка стабильная;
- в начале полоса шире (мало данных), ближе к концу становится заметно уже

---

### 3.4 Комментарий про `B` и константы

Параметр `B` задаёт число регистров `m=2^B`, а значит и ожидаемую дисперсию:
- чем больше `B`, тем больше `m`,
- и тем меньше относительный шум (порядок `1/sqrt(m)`).

Для моего прогона при `B=10` полученное поведение ошибок и разброса соответствует теоретическим формулам из задания.

---

### вывод по Этапу 3

1. По Графику №1 видно, что `N_t` близко повторяет `F0^t` — реализация работает корректно
2. В среднем оценка чуть занижена: `E(err) ≈ -1.25%`

3. Разброс ошибок соответствует теории: `sigma(err) ≈ 2.85%`, что меньше `1.04/sqrt(2^10) ≈ 3.25%` и меньше `1.3/sqrt(2^10) ≈ 4.06%`. 
4.  В среднем есть небольшое занижение (bias ≈ −1.25%), но разброс соответствует теории
5. На ранних шагах шум выше (это ожидаемо), а на больших `t` оценка становится заметно стабильнее
6. в моём прогоне потоков было 5, поэтому на отдельных шагах возможны небольшие всплески `sigma(err)`; при большем числе потоков статистика обычно сглаживается.

## Этап 4 — улучшение HyperLogLog (packed-регистры)

### 1) Изменения
Я изменила только хранение регистров:
- было: `uint8_t` (8 бит на регистр);
- стало: упаковка в 6 бит на регистр (packed6).

Почему: регистр хранит `rho`, а при 32-битном хеше максимум `rho = 32 - B + 1`. Для моего `B=10` это `23`, то есть **6 бит (0..63) достаточно**. Формулы HLL и коррекции я не меняла.

---

### 2) Память
Для `B=10`:
- `m = 2^B = 1024`

Память под регистры:
- baseline: `m * 1 byte = 1024 bytes`
- packed6: `m * 6/8 bytes = 768 bytes`
- экономия: `256 bytes` (**25%**)

---

### 3) Точность и дисперсия
Данные: `stage4_hll_results_all_streams.csv`  
Ошибка: `err = (N_t - F0^t) / F0^t`

Итоги по всем потокам и шагам (100 точек):
- `mean(err_base)    = -0.006342096700`  (−0.6342096700%)
- `std(err_base)     =  0.025053082562`  ( 2.5053082562%)
- `mean(err_packed6) = -0.006342096700`  (−0.6342096700%)
- `std(err_packed6)  =  0.025053082562`  ( 2.5053082562%)

Проверка совпадения оценок:
- `hll_estimate_base == hll_estimate_packed6` для всех строк (`max diff = 0.0`)

---

### 4) Выводы
- **Лучше:** память под регистры стала меньше на **25%**.
- **Не стало хуже:** точность и дисперсия **не изменились**, потому что алгоритм тот же, а `rho` помещается в 6 бит.
Для B=10 максимум rho = 32−B+1 = 23, поэтому 6 бит гарантированно достаточно
- **Оправданность:** усложнение кода оправдано, потому что экономия памяти измеримая, а качество оценки сохраняется.